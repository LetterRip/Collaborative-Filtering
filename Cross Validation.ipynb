{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化变量...\n",
      "------ 第1/5组样本 ------\n",
      "载入训练集dataset/ml-100k/u1.base...\n",
      "载入完成.\n",
      "打分矩阵规模为 943*1682.\n",
      "训练集有效打分个数为 80000.\n",
      "训练集矩阵密度为 5.04%\n",
      "计算训练集各项统计数据...\n",
      "计算总体均值，各user打分均值，各item打分均值...\n",
      "计算相似度矩阵...\n",
      "计算完成.\n",
      "载入测试集dataset/ml-100k/u1.test...\n",
      "测试集大小为 20000\n",
      "测试中...\n",
      "测试完成.\n",
      "------ 第2/5组样本 ------\n",
      "载入训练集dataset/ml-100k/u2.base...\n",
      "载入完成.\n",
      "打分矩阵规模为 943*1682.\n",
      "训练集有效打分个数为 80000.\n",
      "训练集矩阵密度为 5.04%\n",
      "计算训练集各项统计数据...\n",
      "计算总体均值，各user打分均值，各item打分均值...\n",
      "计算相似度矩阵...\n",
      "计算完成.\n",
      "载入测试集dataset/ml-100k/u2.test...\n",
      "测试集大小为 20000\n",
      "测试中...\n",
      "测试完成.\n",
      "------ 第3/5组样本 ------\n",
      "载入训练集dataset/ml-100k/u3.base...\n",
      "载入完成.\n",
      "打分矩阵规模为 943*1682.\n",
      "训练集有效打分个数为 80000.\n",
      "训练集矩阵密度为 5.04%\n",
      "计算训练集各项统计数据...\n",
      "计算总体均值，各user打分均值，各item打分均值...\n",
      "计算相似度矩阵...\n",
      "计算完成.\n",
      "载入测试集dataset/ml-100k/u3.test...\n",
      "测试集大小为 20000\n",
      "测试中...\n",
      "测试完成.\n",
      "------ 第4/5组样本 ------\n",
      "载入训练集dataset/ml-100k/u4.base...\n",
      "载入完成.\n",
      "打分矩阵规模为 943*1682.\n",
      "训练集有效打分个数为 80000.\n",
      "训练集矩阵密度为 5.04%\n",
      "计算训练集各项统计数据...\n",
      "计算总体均值，各user打分均值，各item打分均值...\n",
      "计算相似度矩阵...\n",
      "计算完成.\n",
      "载入测试集dataset/ml-100k/u4.test...\n",
      "测试集大小为 20000\n",
      "测试中...\n",
      "测试完成.\n",
      "------ 第5/5组样本 ------\n",
      "载入训练集dataset/ml-100k/u5.base...\n",
      "载入完成.\n",
      "打分矩阵规模为 943*1682.\n",
      "训练集有效打分个数为 80000.\n",
      "训练集矩阵密度为 5.04%\n",
      "计算训练集各项统计数据...\n",
      "计算总体均值，各user打分均值，各item打分均值...\n",
      "计算相似度矩阵...\n",
      "计算完成.\n",
      "载入测试集dataset/ml-100k/u5.test...\n",
      "测试集大小为 20000\n",
      "测试中...\n",
      "测试完成.\n",
      "------ 测试结果 ------\n",
      "各方法在交叉验证下的RMSE值:\n",
      "baseline:        0.9694\n",
      "itemCF:          1.0149\n",
      "itemCF_baseline: 0.9362\n",
      "userCF_baseline: 0.9548\n",
      "biasCF:          0.9360\n",
      "topkCF(item):    0.9213\n",
      "topkCF(user):    0.9458\n",
      "blend topkCF:    0.9170\n",
      "交叉验证运行完成.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import predict\n",
    "\n",
    "print('初始化变量...')\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "direct = 'dataset/ml-100k/'\n",
    "trainingset_files = (direct + name for name in ('u1.base', 'u2.base', 'u3.base', 'u4.base', 'u5.base'))\n",
    "testset_files = (direct + name for name in ('u1.test', 'u2.test', 'u3.test', 'u4.test', 'u5.test'))\n",
    "n_users = 943\n",
    "n_items = 1682\n",
    "\n",
    "def cal_sparsity():\n",
    "    sparsity = float(len(ratings.nonzero()[0]))\n",
    "    sparsity /= n_users * n_items\n",
    "    sparsity *= 100\n",
    "    print('训练集矩阵密度为 {:4.2f}%'.format(sparsity))\n",
    "\n",
    "def rmse(pred, actual):\n",
    "    '''计算预测结果的rmse'''\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return np.sqrt(mean_squared_error(pred, actual))\n",
    "\n",
    "def cal_mean():\n",
    "    '''Calculate mean value'''\n",
    "    print('计算总体均值，各user打分均值，各item打分均值...')\n",
    "    global all_mean, user_mean, item_mean\n",
    "    all_mean = np.mean(ratings[ratings!=0])\n",
    "    user_mean = sum(ratings.T) / sum((ratings!=0).T)\n",
    "    item_mean = sum(ratings) / sum((ratings!=0))\n",
    "    user_mean = np.where(np.isnan(user_mean), all_mean, user_mean)\n",
    "    item_mean = np.where(np.isnan(item_mean), all_mean, item_mean)\n",
    "    \n",
    "def cal_similarity(ratings, kind, epsilon=1e-9):\n",
    "    '''利用Cosine距离计算相似度'''\n",
    "    '''epsilon: 防止Divide-by-zero错误，进行矫正'''\n",
    "    if kind == 'user':\n",
    "        sim = ratings.dot(ratings.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        sim = ratings.T.dot(ratings) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)\n",
    "\n",
    "def predict_baseline(user, item):\n",
    "    prediction = item_mean[item] + user_mean[user] - all_mean\n",
    "    return prediction\n",
    "\n",
    "def predict_itemCF(user, item, k=100):\n",
    "    '''item-item协同过滤算法,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    prediction = ratings[user, nzero].dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero])\n",
    "    return prediction\n",
    "\n",
    "def predict_itemCF_baseline(user, item, k=100):\n",
    "    '''结合baseline的item-item CF算法,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    prediction = (ratings[user, nzero] - baseline[nzero]).dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero]) + baseline[item]\n",
    "    return prediction \n",
    "\n",
    "def predict_userCF_baseline(user, item, k=100):\n",
    "    '''结合baseline的user-user协同过滤算法,预测rating'''\n",
    "    nzero = ratings[:,item].nonzero()[0]\n",
    "    baseline = user_mean + item_mean[item] - all_mean\n",
    "    prediction = (ratings[nzero, item] - baseline[nzero]).dot(user_similarity[user, nzero])\\\n",
    "                / sum(user_similarity[user, nzero]) + baseline[user]\n",
    "    if np.isnan(prediction):\n",
    "        prediction = baseline[user]\n",
    "    return prediction\n",
    "\n",
    "def predict_biasCF(user, item, k=100):\n",
    "    '''结合baseline的item-item CF算法,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    prediction = (ratings[user, nzero] - baseline[nzero]).dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero]) + baseline[item]\n",
    "    if prediction > 5:\n",
    "        prediction = 5\n",
    "    if prediction < 1:\n",
    "        prediciton = 1\n",
    "    return prediction\n",
    "\n",
    "def predict_topkCF_item(user, item, k=20):\n",
    "    '''top-k CF算法,以item-item协同过滤为基础，结合baseline,预测rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    choice = nzero[item_similarity[item, nzero].argsort()[::-1][:k]]\n",
    "    prediction = (ratings[user, choice] - baseline[choice]).dot(item_similarity[item, choice])\\\n",
    "                / sum(item_similarity[item, choice]) + baseline[item]\n",
    "    if prediction > 5: prediction = 5\n",
    "    if prediction < 1: prediction = 1\n",
    "    return prediction\n",
    "\n",
    "def predict_topkCF_user(user, item, k=20):\n",
    "    '''top-k CF算法,以user-user协同过滤为基础，结合baseline,预测rating'''    \n",
    "    nzero = ratings[:,item].nonzero()[0]\n",
    "    choice = nzero[user_similarity[user, nzero].argsort()[::-1][:k]]\n",
    "    baseline = user_mean + item_mean[item] - all_mean\n",
    "    prediction = (ratings[choice, item] - baseline[choice]).dot(user_similarity[user, choice])\\\n",
    "                / sum(user_similarity[user, choice]) + baseline[user]\n",
    "    if np.isnan(prediction):\n",
    "        prediction = baseline[user]\n",
    "    if prediction > 5: prediction = 5\n",
    "    if prediction < 1: prediction = 1\n",
    "    return prediction\n",
    "\n",
    "def predict_blend(user, item, k1=20, k2=20):\n",
    "    prediction1 = predict_topkCF(user, item, k1)\n",
    "    prediction2 = predict_topkCF_user(user, item, k2)\n",
    "    prediction = (prediction1 + prediction2) / 2\n",
    "    if prediction > 5: prediction = 5\n",
    "    if prediction < 1: prediction = 1\n",
    "    return prediction\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    method = {'baseline', 'itemCF', 'itemCF_baseline', 'userCF_baseline', 'itemCF_bias', 'topkCF_item', 'topkCF_user'}\n",
    "    rmse_baseline = []\n",
    "    rmse_itemCF = []\n",
    "    rmse_itemCF_baseline = []\n",
    "    rmse_userCF_baseline = []\n",
    "    rmse_itemCF_bias = []\n",
    "    rmse_topkCF_item = []\n",
    "    rmse_topkCF_user = []\n",
    "    rmse_blend = []\n",
    "    i = 0\n",
    "    nums = 5\n",
    "    for trainingset_file, testset_file in zip(trainingset_files, testset_files):\n",
    "        i += 1\n",
    "        print('------ 第%d/%d组样本 ------' % (i, nums))\n",
    "        df = pd.read_csv(trainingset_file, sep='\\t', names=names)\n",
    "        \n",
    "        ratings = np.zeros((n_users, n_items))\n",
    "        print('载入训练集' + trainingset_file + '...')\n",
    "        for row in df.itertuples():\n",
    "            ratings[row[1]-1, row[2]-1] = row[3]\n",
    "        \n",
    "        print('载入完成.')\n",
    "        print('打分矩阵规模为 %d*%d.' % (n_users, n_items))\n",
    "        print('训练集有效打分个数为 %d.' % len(df))\n",
    "\n",
    "        cal_sparsity()\n",
    "        print('计算训练集各项统计数据...')\n",
    "        cal_mean()\n",
    "\n",
    "        print('计算相似度矩阵...')\n",
    "        user_similarity = cal_similarity(ratings, kind='user')\n",
    "        item_similarity = cal_similarity(ratings, kind='item')\n",
    "        print('计算完成.')\n",
    "        \n",
    "        print('载入测试集' + testset_file + '...')\n",
    "        test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "        test_df.head()\n",
    "        predictions_baseline = []\n",
    "        predictions_itemCF = []\n",
    "        predictions_itemCF_baseline = []\n",
    "        predictions_userCF_baseline = []\n",
    "        predictions_itemCF_bias = []\n",
    "        predictions_topkCF_item = []\n",
    "        predictions_topkCF_user = []\n",
    "        predictions_blend = []\n",
    "        targets = []\n",
    "        print('测试集大小为 %d' % len(test_df))\n",
    "        print('测试中...')\n",
    "        for row in test_df.itertuples():\n",
    "            user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "            predictions_baseline.append(predict_baseline(user, item))\n",
    "            predictions_itemCF.append(predict_itemCF(user, item))\n",
    "            predictions_itemCF_baseline.append(predict_itemCF_baseline(user, item))\n",
    "            predictions_userCF_baseline.append(predict_userCF_baseline(user, item))\n",
    "            predictions_itemCF_bias.append(predict_biasCF(user, item))\n",
    "            predictions_topkCF_item.append(predict_topkCF(user, item, 20))\n",
    "            predictions_topkCF_user.append(predict_topkCF_user(user, item, 20))\n",
    "            predictions_blend.append(predict_blend(user, item, 20, 20))\n",
    "            targets.append(actual)\n",
    "    \n",
    "        rmse_baseline.append(rmse(np.array(predictions_baseline), np.array(targets)))\n",
    "        rmse_itemCF.append(rmse(np.array(predictions_itemCF), np.array(targets)))\n",
    "        rmse_itemCF_baseline.append(rmse(np.array(predictions_itemCF_baseline), np.array(targets)))\n",
    "        rmse_userCF_baseline.append(rmse(np.array(predictions_userCF_baseline), np.array(targets)))\n",
    "        rmse_itemCF_bias.append(rmse(np.array(predictions_itemCF_bias), np.array(targets)))\n",
    "        rmse_topkCF_item.append(rmse(np.array(predictions_topkCF_item), np.array(targets)))\n",
    "        rmse_topkCF_user.append(rmse(np.array(predictions_topkCF_user), np.array(targets)))\n",
    "        rmse_blend.append(rmse(np.array(predictions_blend), np.array(targets)))\n",
    "        print('测试完成.')\n",
    "    print('------ 测试结果 ------')\n",
    "    print('各方法在交叉验证下的RMSE值:')\n",
    "    print('baseline:        %.4f' % np.mean(rmse_baseline))\n",
    "    print('itemCF:          %.4f' % np.mean(rmse_itemCF))\n",
    "    print('itemCF_baseline: %.4f' % np.mean(rmse_itemCF_baseline))\n",
    "    print('userCF_baseline: %.4f' % np.mean(rmse_userCF_baseline)) \n",
    "    print('biasCF:          %.4f' % np.mean(rmse_itemCF_bias))\n",
    "    print('topkCF(item):    %.4f' % np.mean(rmse_topkCF_item))\n",
    "    print('topkCF(user):    %.4f' % np.mean(rmse_topkCF_user))\n",
    "    print('blend topkCF:    %.4f' % np.mean(rmse_blend))\n",
    "    print('交叉验证运行完成.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

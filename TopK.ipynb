{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化变量...\n",
      "------ 第1/5组样本 ------\n",
      "载入训练集dataset/ml-100k/u1.base\n",
      "计算训练集各项统计数据...\n",
      "计算相似度矩阵...\n",
      "计算完成\n",
      "在训练集上测试...\n",
      "载入测试集dataset/ml-100k/u1.test\n",
      "测试集规模为 20000\n",
      "在测试集上测试...\n",
      "测试完成\n",
      "------ 第2/5组样本 ------\n",
      "载入训练集dataset/ml-100k/u2.base\n",
      "计算训练集各项统计数据...\n",
      "计算相似度矩阵...\n",
      "计算完成\n",
      "在训练集上测试...\n",
      "载入测试集dataset/ml-100k/u2.test\n",
      "测试集规模为 20000\n",
      "在测试集上测试...\n",
      "测试完成\n",
      "------ 第3/5组样本 ------\n",
      "载入训练集dataset/ml-100k/u3.base\n",
      "计算训练集各项统计数据...\n",
      "计算相似度矩阵...\n",
      "计算完成\n",
      "在训练集上测试...\n",
      "载入测试集dataset/ml-100k/u3.test\n",
      "测试集规模为 20000\n",
      "在测试集上测试...\n",
      "测试完成\n",
      "------ 第4/5组样本 ------\n",
      "载入训练集dataset/ml-100k/u4.base\n",
      "计算训练集各项统计数据...\n",
      "计算相似度矩阵...\n",
      "计算完成\n",
      "在训练集上测试...\n",
      "载入测试集dataset/ml-100k/u4.test\n",
      "测试集规模为 20000\n",
      "在测试集上测试...\n",
      "测试完成\n",
      "------ 第5/5组样本 ------\n",
      "载入训练集dataset/ml-100k/u5.base\n",
      "计算训练集各项统计数据...\n",
      "计算相似度矩阵...\n",
      "计算完成\n",
      "在训练集上测试...\n",
      "载入测试集dataset/ml-100k/u5.test\n",
      "测试集规模为 20000\n",
      "在测试集上测试...\n",
      "测试完成\n",
      "------ 测试结果 ------\n",
      "item-item协同过滤算法中, 各K值在训练集上的RMSE:\n",
      "k =   5:   0.5747\n",
      "k =  10:   0.6845\n",
      "k =  15:   0.7322\n",
      "k =  18:   0.7500\n",
      "k =  20:   0.7596\n",
      "k =  25:   0.7774\n",
      "k =  30:   0.7902\n",
      "k =  40:   0.8073\n",
      "k =  50:   0.8182\n",
      "k = 100:   0.8422\n",
      "k = 200:   0.8546\n",
      "item-item协同过滤算法中, 各K值在测试集上的RMSE:\n",
      "k =   5:   0.9543\n",
      "k =  10:   0.9278\n",
      "k =  15:   0.9223\n",
      "k =  18:   0.9215\n",
      "k =  20:   0.9213\n",
      "k =  25:   0.9217\n",
      "k =  30:   0.9225\n",
      "k =  40:   0.9242\n",
      "k =  50:   0.9258\n",
      "k = 100:   0.9314\n",
      "k = 200:   0.9345\n",
      "user-user协同过滤算法中, 各K值在训练集上的RMSE:\n",
      "k =   5:   0.6101\n",
      "k =  10:   0.7242\n",
      "k =  15:   0.7699\n",
      "k =  18:   0.7866\n",
      "k =  20:   0.7951\n",
      "k =  25:   0.8113\n",
      "k =  30:   0.8225\n",
      "k =  40:   0.8373\n",
      "k =  50:   0.8465\n",
      "k = 100:   0.8660\n",
      "k = 200:   0.8747\n",
      "user-user协同过滤算法中, 各K值在测试集上的RMSE:\n",
      "k =   5:   0.9874\n",
      "k =  10:   0.9573\n",
      "k =  15:   0.9489\n",
      "k =  18:   0.9468\n",
      "k =  20:   0.9458\n",
      "k =  25:   0.9449\n",
      "k =  30:   0.9445\n",
      "k =  40:   0.9447\n",
      "k =  50:   0.9453\n",
      "k = 100:   0.9491\n",
      "k = 200:   0.9526\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import var\n",
    "import predict as pre\n",
    "import utils\n",
    "\n",
    "print('初始化变量...')\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "direct = 'dataset/ml-100k/'\n",
    "trainingset_files = (direct + name for name in ('u1.base', 'u2.base', 'u3.base', 'u4.base', 'u5.base'))\n",
    "testset_files = (direct + name for name in ('u1.test', 'u2.test', 'u3.test', 'u4.test', 'u5.test'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    i = 0\n",
    "    nums = 5\n",
    "    k_set = [5, 10, 15, 18, 20, 25, 30, 40, 50, 100, 200]\n",
    "    rmse_topkCF_item_train = {k:[] for k in k_set}\n",
    "    rmse_topkCF_user_train = {k:[] for k in k_set}\n",
    "    rmse_topkCF_item = {k:[] for k in k_set}\n",
    "    rmse_topkCF_user = {k:[] for k in k_set}\n",
    "    for trainingset_file, testset_file in zip(trainingset_files, testset_files):\n",
    "        i += 1\n",
    "        print('------ 第%d/%d组样本 ------' % (i, nums))\n",
    "        df = pd.read_csv(trainingset_file, sep='\\t', names=names)\n",
    "        \n",
    "        var.ratings = np.zeros((var.n_users, var.n_items))\n",
    "        print('载入训练集' + trainingset_file)\n",
    "        for row in df.itertuples():\n",
    "            var.ratings[row[1]-1, row[2]-1] = row[3]\n",
    "          \n",
    "        print('计算训练集各项统计数据...')\n",
    "        utils.cal_mean()\n",
    "\n",
    "        print('计算相似度矩阵...')\n",
    "        var.user_similarity = utils.cal_similarity(kind='user')\n",
    "        var.item_similarity = utils.cal_similarity(kind='item')\n",
    "        print('计算完成')\n",
    "\n",
    "        predictions_topkCF_item_train = {k:[] for k in k_set}\n",
    "        predictions_topkCF_user_train = {k:[] for k in k_set}\n",
    "        targets = []\n",
    "        print('在训练集上测试...')\n",
    "        for row in df.itertuples():\n",
    "            user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "            for k in k_set:\n",
    "                predictions_topkCF_item_train[k].append(pre.predict_topkCF_item(user, item, k))\n",
    "                predictions_topkCF_user_train[k].append(pre.predict_topkCF_user(user, item, k))\n",
    "            targets.append(actual)\n",
    "        for k in k_set:\n",
    "            rmse_topkCF_item_train[k].append(utils.rmse(np.array(predictions_topkCF_item_train[k]), np.array(targets)))\n",
    "            rmse_topkCF_user_train[k].append(utils.rmse(np.array(predictions_topkCF_user_train[k]), np.array(targets)))    \n",
    "        \n",
    "        print('载入测试集' + testset_file)\n",
    "        test_df = pd.read_csv(testset_file, sep='\\t', names=names)        \n",
    "        predictions_topkCF_item = {k:[] for k in k_set}\n",
    "        predictions_topkCF_user = {k:[] for k in k_set}\n",
    "        targets = []\n",
    "        print('测试集规模为 %d' % len(test_df))\n",
    "        print('在测试集上测试...')\n",
    "        for row in test_df.itertuples():\n",
    "            user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "            for k in k_set:\n",
    "                predictions_topkCF_item[k].append(pre.predict_topkCF_item(user, item, k))\n",
    "                predictions_topkCF_user[k].append(pre.predict_topkCF_user(user, item, k))\n",
    "            targets.append(actual)\n",
    "        for k in k_set:\n",
    "            rmse_topkCF_item[k].append(utils.rmse(np.array(predictions_topkCF_item[k]), np.array(targets)))\n",
    "            rmse_topkCF_user[k].append(utils.rmse(np.array(predictions_topkCF_user[k]), np.array(targets)))            \n",
    "        print('测试完成')\n",
    "        \n",
    "    print('------ 测试结果 ------')\n",
    "    \n",
    "    print('item-item协同过滤算法中, 各K值在训练集上的RMSE:')\n",
    "    for k in sorted(k_set):\n",
    "        print('k = %3d:   %.4f' % (k, np.mean(rmse_topkCF_item_train[k])))\n",
    "    print('item-item协同过滤算法中, 各K值在测试集上的RMSE:')\n",
    "    for k in sorted(k_set):\n",
    "        print('k = %3d:   %.4f' % (k, np.mean(rmse_topkCF_item[k])))\n",
    "    print('user-user协同过滤算法中, 各K值在训练集上的RMSE:')\n",
    "    for k in sorted(k_set):\n",
    "        print('k = %3d:   %.4f' % (k, np.mean(rmse_topkCF_user_train[k])))\n",
    "    print('user-user协同过滤算法中, 各K值在测试集上的RMSE:')\n",
    "    for k in sorted(k_set):\n",
    "        print('k = %3d:   %.4f' % (k, np.mean(rmse_topkCF_user[k])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
